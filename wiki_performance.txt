===========================================================
Top Multi-Layered Perceptron Model for --> Emotions
Provided Hyper-Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]}
Best Estimator: MLPClassifier(activation='logistic', batch_size=300, hidden_layer_sizes=(80,),
              learning_rate_init=0.01, max_iter=30)
Best Parameters: {'activation': 'logistic', 'batch_size': 300, 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 30, 'solver': 'adam'}
===========================================================

Confusion Matrix:
-----------------

[[  743    18     4     3     1     3     0     4     0     0     3     7     0     2     3    38     0    17    79     0  1184    18     0     0     0     0     4     3]
 [   43   277     3     0     0     0     0     9     0     0     4     9     0     1     5    15     0    13    19     0   826     0     0     0     0     0     6     3]
 [   10    10    69    20     0     0     0     9     1     0     3    24     0     0     1     3     0     1     2     0   900     0     0     0     0     0     9     0]
 [   27    22    25    26     1     3     3    12     2     1     5    31     0     0     6     7     1     3    23     0  1459     2     0     0     0     2    26     1]
 [   84    15     1     4    19     3     0     7     0     2     9     5     0     0     5    17     1     7    48     0  1972     5     0     0     0     2    20     0]
 [   16     5     2     1     0    17     0     1     1     0     0     0     0     0     2    23     1     7    14     0   549    10     0     0     0     3    17     0]
 [    7    13     2     3     0     0     5    65     0     0     3     2     0     0     0     6     0     0     7     0   845     0     0     0     0     0     6     1]
 [    4     3     2     4     0     0     7   146     0     0     1     2     0     2     1     4     0     2     6     0   949     4     0     0     0     0     4     2]
 [   12     2     0     1     0     1     0     1    25     0     0     0     0     0     1     3     0     2    19     0   359     9     0     0     0     2     2     0]
 [   12     7     5     5     0     0     0     2     0     8     4    14     0     0     9     4     0     1     9     0   850     2     0     0     0     2    36     0]
 [   11    18     7     5     0     2     3     6     0     2    39    14     1     0     4     8     0     4     9     0  1383     2     0     0     0     1    18     0]
 [    5     5    14     8     0     0     0     0     0     2     2    69     0     0     7     2     0     1     2     0   457     1     0     0     0     1     9     0]
 [    4     5     1     3     0     0     0     3     0     0     1     6     2     0     0     1     0     0     3     0   265     1     0     0     0     0     7     1]
 [   44     5     3     0     0     0     0     6     0     0     0     1     0    11     0    17     0    12    14     0   474     5     0     0     0     0     2     3]
 [    3     3     0     1     0     0     0     0     0     0     1    10     0     0    45     0     1     1     1     0   242     1     0     0     0     0     8     0]
 [   92     4     0     0     0    12     0     3     1     0     0     2     0     3     0   462     1     9    24     0   770    10     0     0     0     3    11     2]
 [    1     0     0     0     0     1     0     1     0     0     0     0     0     0     1     1     0     0     0     0    47     0     0     0     0     0     6     0]
 [   73    39     1     1     0     3     0     5     0     0     1     0     0     9     0    15     1    60    53     0   534     6     0     0     0     0    13     0]
 [   57     7     2     1     0     2     0     2     0     0     0     0     0     1     0    11     1     9   392     0   510     3     0     0     0     1     4     1]
 [    1     1     1     1     0     0     1     0     1     0     0     3     0     0     8     0     0     0     0     2   161     0     0     0     0     0     7     0]
 [  236    99    27    27     4    23     6   137     5     3    31    37     0     7    21    52     7    28   105     0 10099    21     0     0     0     5    75    12]
 [   41     5     1     0     0     2     0     2     4     0     4     1     0     0     4    23     1     7     9     0   721    79     0     0     0     0     9     1]
 [   22     2     0     0     0     0     0     1     0     0     0     1     0     1     0     1     0     3     0     0   122     1     2     0     0     0     1     0]
 [    8     9     1     1     0     0     0     2     0     0     1     3     0     1     1     6     1     1     9     0   919     1     0     0     0     0     5     3]
 [   14     3     0     0     1     1     0     0     0     0     0     0     0     0     0     5     0     0     1     0   123     2     0     0     0     0     6     0]
 [    2     5     1     2     0     1     0     1     0     0     0     0     0     0     2     4     0     1     0     0   193     1     0     0     0    31    28     0]
 [    3     6     6     0     0     1     0     4     0     7     2     7     0     0     4     8     3     1    13     0   567     2     0     0     0    22   138     1]
 [   23     5     3     1     1     1     0    21     0     0     4     4     0     0     2     4     0     2     4     0   598     2     0     0     0     0     3    13]]

Classification Report:
----------------------

                precision    recall  f1-score   support

    admiration       0.46      0.35      0.40      2134
     amusement       0.47      0.22      0.30      1233
         anger       0.38      0.06      0.11      1062
     annoyance       0.22      0.02      0.03      1688
      approval       0.70      0.01      0.02      2226
        caring       0.22      0.03      0.05       669
     confusion       0.20      0.01      0.01       965
     curiosity       0.32      0.13      0.18      1143
        desire       0.62      0.06      0.10       439
disappointment       0.32      0.01      0.02       970
   disapproval       0.33      0.03      0.05      1537
       disgust       0.27      0.12      0.16       585
 embarrassment       0.67      0.01      0.01       303
    excitement       0.29      0.02      0.03       597
          fear       0.34      0.14      0.20       317
     gratitude       0.62      0.33      0.43      1409
         grief       0.00      0.00      0.00        58
           joy       0.31      0.07      0.12       814
          love       0.45      0.39      0.42      1004
   nervousness       1.00      0.01      0.02       187
       neutral       0.36      0.91      0.52     11067
      optimism       0.42      0.09      0.14       914
         pride       1.00      0.01      0.03       157
   realization       0.00      0.00      0.00       972
        relief       0.00      0.00      0.00       156
       remorse       0.41      0.11      0.18       272
       sadness       0.29      0.17      0.22       795
      surprise       0.28      0.02      0.04       691

      accuracy                           0.37     34364
     macro avg       0.39      0.12      0.14     34364
  weighted avg       0.38      0.37      0.27     34364


===========================================================
Top Multi-Layered Perceptron Model for --> Sentiments
Provided Hyper-Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]}
Best Estimator: MLPClassifier(activation='logistic', batch_size=300, hidden_layer_sizes=(80,),
              learning_rate_init=0.01, max_iter=30)
Best Parameters: {'activation': 'logistic', 'batch_size': 300, 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 30, 'solver': 'adam'}
===========================================================

Confusion Matrix:
-----------------

[[ 847  618 1371  935]
 [ 289 3265 2460 1760]
 [ 670 1890 5279 3228]
 [ 295 1163 2781 7513]]

Classification Report:
----------------------

              precision    recall  f1-score   support

   ambiguous       0.40      0.22      0.29      3771
    negative       0.47      0.42      0.44      7774
     neutral       0.44      0.48      0.46     11067
    positive       0.56      0.64      0.60     11752

    accuracy                           0.49     34364
   macro avg       0.47      0.44      0.45     34364
weighted avg       0.48      0.49      0.48     34364


