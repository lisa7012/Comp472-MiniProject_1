===========================================================
Top Multi-Layered Perceptron Model for --> Emotions
(Hyper Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]})
===========================================================

Confusion Matrix:
-----------------

[[ 921   16    7    4   13    9    3    9    2    2    2    3    1    6    3   75    0   26   95    0  899   24    3    0    2    0    3    6]
 [  46  314    5    8    2    5    4   10    3    0    5    5    1    1    2   26    0   24   16    0  736    2    0    1    0    0   10    7]
 [   7    7  107   39    2    7    7   10    2    1    6   12    0    1    7   11    0    2    1    1  820    3    0    0    0    1    7    1]
 [  28   21   53   61    3    6   14   22    3    6   11   22    1    3    9   11    0    4   19    2 1369    4    0    0    0    2   10    4]
 [ 116   14    3    5   72   25    2   14    8    3   12    3    0    3    4   43    0   14   44    2 1804   20    0    2    0    5    7    1]
 [  24    2    0    2    4   75    1    3    3    0    2    1    0    1    1   34    0    5   11    2  457   26    0    0    0    7    8    0]
 [  11    9    1    4    1    3   68  104    0    1   14    0    0    0    3    5    0    2    6    1  724    0    0    1    0    1    4    2]
 [   8    3    4    5    0    1   54  270    3    1    0    0    0    0    1    9    0    4    7    1  761    7    0    1    0    0    1    2]
 [  21    2    1    0    1    3    3    4   46    0    0    0    0    1    1    6    0    3   17    0  299   29    0    0    0    0    2    0]
 [  21    5   10    7    1    5    5    6    3   17   11    8    1    0    7    6    0    1    9    0  794    8    0    2    0    6   32    5]
 [  25   15    9   16    4    3    7   12    2    3   72   12    1    0    5   14    0    5   10    1 1298    8    0    3    0    1    7    4]
 [   7    5   18   20    0    3    0    3    2    4    1   70    0    1   12    4    0    0    3    0  425    1    0    0    0    0    4    2]
 [   3    1    0    7    0    0    4    5    0    1    1    3   10    0    2    4    0    1    3    2  250    1    0    0    0    3    1    1]
 [  51    4    4    0    1    1    2   13    2    1    0    0    0   44    1   24    0   13   21    3  399   10    0    0    0    0    1    2]
 [   6    3    2    0    1    2    2    2    0    1    1    9    0    0   81    0    0    0    0    6  199    1    0    0    0    0    1    0]
 [  82    7    2    0    4   17    2    7    1    0    0    0    0    5    0  724    0   19   15    1  487   24    0    0    0    6    4    2]
 [   1    0    1    0    0    0    0    0    0    0    0    0    0    0    3    0    1    0    0    1   43    2    0    0    0    0    6    0]
 [  82   45    0    2    2    9    1    3    3    2    2    0    0   11    2   36    0  127   54    0  414   10    1    0    1    0    6    1]
 [  67    6    2    2    1    7    1    3    4    0    1    0    0    1    1   15    0   16  487    0  381    5    0    0    0    1    3    0]
 [   2    2    1    2    0    4    1    3    0    2    0    1    1    0    9    1    0    0    0   16  135    2    0    0    0    1    4    0]
 [ 307   94   58   47   29   81   71  225   28   11   71   17    5   19   37  130    1   55   91   11 9539   52    2    3    3   14   50   16]
 [  45    7    0    1    2   37    1    8   11    1    4    0    0    3    0   33    1    9   10    0  571  162    0    0    0    0    7    1]
 [  25    1    0    0    0    0    1    1    0    0    0    0    0    1    0    9    0    3    1    0  110    2    2    0    0    0    1    0]
 [  18    8    1    3    5    4    6    7    2    2    5    4    0    0    3   12    1    5   10    0  851    2    0    9    1    1    5    7]
 [  13    1    0    0    1    5    0    1    0    1    0    0    0    0    0   18    0    8    1    1   97    4    0    0    1    0    4    0]
 [   3    5    0    0    1    7    1    2    0    0    0    0    1    0    0   14    0    1    0    1  168    4    0    1    0   51   11    1]
 [   7    8    4    2    0    3    2    9    0   14    8    3    1    0    6   11    0    2    8    2  540    5    0    2    0   32  126    0]
 [  36    3    5    3    2    2   11   18    0    3    8    1    0    3    2    7    1    6    3    0  524    5    0    0    0    0    2   46]]

Classification Report:
----------------------

                precision    recall  f1-score   support

    admiration       0.46      0.43      0.45      2134
     amusement       0.52      0.25      0.34      1233
         anger       0.36      0.10      0.16      1062
     annoyance       0.25      0.04      0.06      1688
      approval       0.47      0.03      0.06      2226
        caring       0.23      0.11      0.15       669
     confusion       0.25      0.07      0.11       965
     curiosity       0.35      0.24      0.28      1143
        desire       0.36      0.10      0.16       439
disappointment       0.22      0.02      0.03       970
   disapproval       0.30      0.05      0.08      1537
       disgust       0.40      0.12      0.18       585
 embarrassment       0.43      0.03      0.06       303
    excitement       0.42      0.07      0.13       597
          fear       0.40      0.26      0.31       317
     gratitude       0.56      0.51      0.54      1409
         grief       0.20      0.02      0.03        58
           joy       0.36      0.16      0.22       814
          love       0.52      0.49      0.50      1004
   nervousness       0.30      0.09      0.13       187
       neutral       0.38      0.86      0.53     11067
      optimism       0.38      0.18      0.24       914
         pride       0.25      0.01      0.02       157
   realization       0.36      0.01      0.02       972
        relief       0.12      0.01      0.01       156
       remorse       0.39      0.19      0.25       272
       sadness       0.39      0.16      0.22       795
      surprise       0.41      0.07      0.11       691

      accuracy                           0.39     34364
     macro avg       0.36      0.17      0.19     34364
  weighted avg       0.38      0.39      0.31     34364


===========================================================
Top Multi-Layered Perceptron Model for --> Sentiments
(Hyper Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]})
===========================================================

Confusion Matrix:
-----------------

[[1106  625 1332  708]
 [ 325 3789 2336 1324]
 [ 772 2126 5500 2669]
 [ 312 1212 2809 7419]]

Classification Report:
----------------------

              precision    recall  f1-score   support

   ambiguous       0.44      0.29      0.35      3771
    negative       0.49      0.49      0.49      7774
     neutral       0.46      0.50      0.48     11067
    positive       0.61      0.63      0.62     11752

    accuracy                           0.52     34364
   macro avg       0.50      0.48      0.48     34364
weighted avg       0.52      0.52      0.52     34364


