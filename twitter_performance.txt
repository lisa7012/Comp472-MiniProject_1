===========================================================
Top Multi-Layered Perceptron Model for --> Emotions
Provided Hyper-Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]}
Best Estimator: MLPClassifier(activation='logistic', batch_size=300, hidden_layer_sizes=(80,),
              learning_rate_init=0.01, max_iter=30)
Best Parameters: {'activation': 'logistic', 'batch_size': 300, 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 30, 'solver': 'adam'}
===========================================================

Confusion Matrix:
-----------------

[[ 902   24    8    4   12    6    2    5    5    2    3    3    1    7    5   74    0   25  100    0  918   16    4    0    1    1    4    2]
 [  39  383    8    9    5    1    4    7    3    0    2    1    1    1    2   26    0   16   20    0  692    1    0    1    0    2    8    1]
 [  10    8  127   20    1    2    2    8    2    0    6   11    1    1    8   10    0    2    3    0  830    1    0    0    0    1    7    1]
 [  31   25   69   42    3    3    8   12    6   10   11   14    4    2   13   16    0    5   17    2 1376    4    0    0    0    1   11    3]
 [ 102   27    7    2   66   11    2   10    4    2   19    1    1    5    8   61    1   11   41    0 1814    6    0    0    1    3   17    4]
 [  26    5    0    0    3   39    1    2    2    0    3    1    0    0    2   51    0    6   14    2  477   23    0    0    0    8    4    0]
 [  13   10    3    6    0    1   45   93    0    1    6    0    0    1    3   11    0    1    6    0  757    0    0    1    0    1    5    1]
 [  10    3    7    1    0    0   48  225    3    1    0    0    0    1    5   11    0    1    8    0  812    2    0    0    0    0    3    2]
 [  19    5    1    0    0    0    1    2   56    0    0    0    0    1    2    7    0    7   16    0  310   10    0    0    0    1    1    0]
 [  16    7   13    5    0    2    3    6    3   20    8    7    0    0   12    6    0    2   10    0  794    3    0    1    0    6   41    5]
 [  15   24   12   12    6    5    3   12    1    9   59   14    2    0    6   17    0    3   12    0 1309    2    0    1    0    0    7    6]
 [   3    7   22   17    1    4    1    2    2    2    4   65    1    1   22    5    0    0    3    0  414    1    0    0    0    0    6    2]
 [   6    3    3    2    0    0    4    0    0    2    2    2   16    0    1    4    0    0    3    1  248    1    0    0    0    2    3    0]
 [  45    9    5    0    1    0    1    5    2    1    0    0    0   43    2   16    0   16   18    0  426    1    0    0    0    0    3    3]
 [   4    5    1    0    0    2    0    0    0    2    0    6    1    0   90    1    0    0    0    2  202    1    0    0    0    0    0    0]
 [  82    8    4    1    3   11    1    9    3    3    1    0    0    5    0  748    0   22   17    1  462   15    0    0    4    5    4    0]
 [   2    0    1    0    0    0    0    0    0    1    0    0    0    0    2    2    1    0    1    0   39    0    0    0    0    1    8    0]
 [  76   50    0    2    0    6    0    1    2    1    0    0    0    9    5   45    1  112   56    0  436    3    0    0    2    0    6    1]
 [  57    9    3    2    0    6    0    0    5    1    0    0    0    0    0   18    0    9  540    0  348    4    0    0    0    0    1    1]
 [   1    1    1    0    0    0    1    3    0    0    0    0    1    0   10    2    0    1    0   18  141    0    0    0    0    1    6    0]
 [ 285  141   66   28   37   39   46  199   28   18   60   35    6   16   48  158    1   44  122    4 9587   23    3    0    0   15   46   12]
 [  48    7    1    1    1   18    0    5   14    2    3    0    0    1    1   52    0   10   11    0  621  112    0    0    0    0    5    1]
 [  21    2    0    0    0    0    0    0    0    1    1    0    1    2    0    6    0    4    0    0  112    2    4    0    0    0    1    0]
 [  23   12    2    1    5    3    1    9    1    2    5    1    0    0    7   13    0    2    9    0  860    1    0    6    0    2    4    3]
 [  13    1    0    0    0    3    0    0    0    2    1    0    0    0    0   15    0    5    2    0  109    1    0    0    2    0    2    0]
 [   3    6    0    0    1    1    0    3    1    1    1    0    1    0    0   21    0    2    1    1  171    0    0    0    0   40   17    1]
 [   6   10    5    1    2    4    1    6    2   11    4    2    2    0   12   13    1    3   12    1  526    3    0    2    0   34  132    0]
 [  22   11    7    1    1    0    7   11    0    3   12    2    1    6    2    9    0    2    2    0  551    1    0    0    0    1    3   36]]

Classification Report:
----------------------

                precision    recall  f1-score   support

    admiration       0.48      0.42      0.45      2134
     amusement       0.48      0.31      0.38      1233
         anger       0.34      0.12      0.18      1062
     annoyance       0.27      0.02      0.05      1688
      approval       0.45      0.03      0.06      2226
        caring       0.23      0.06      0.09       669
     confusion       0.25      0.05      0.08       965
     curiosity       0.35      0.20      0.25      1143
        desire       0.39      0.13      0.19       439
disappointment       0.20      0.02      0.04       970
   disapproval       0.28      0.04      0.07      1537
       disgust       0.39      0.11      0.17       585
 embarrassment       0.40      0.05      0.09       303
    excitement       0.42      0.07      0.12       597
          fear       0.34      0.28      0.31       317
     gratitude       0.53      0.53      0.53      1409
         grief       0.20      0.02      0.03        58
           joy       0.36      0.14      0.20       814
          love       0.52      0.54      0.53      1004
   nervousness       0.56      0.10      0.16       187
       neutral       0.38      0.87      0.53     11067
      optimism       0.47      0.12      0.19       914
         pride       0.36      0.03      0.05       157
   realization       0.50      0.01      0.01       972
        relief       0.20      0.01      0.02       156
       remorse       0.32      0.15      0.20       272
       sadness       0.37      0.17      0.23       795
      surprise       0.42      0.05      0.09       691

      accuracy                           0.39     34364
     macro avg       0.37      0.17      0.19     34364
  weighted avg       0.39      0.39      0.31     34364


===========================================================
Top Multi-Layered Perceptron Model for --> Sentiments
Provided Hyper-Parameters: {'activation': ('relu', 'logistic'), 'hidden_layer_sizes': ((80,), (10, 10)), 'solver': ('adam', 'sgd'), 'max_iter': [30], 'learning_rate_init': [0.01], 'learning_rate': ['constant'], 'batch_size': [300]}
Best Estimator: MLPClassifier(activation='logistic', batch_size=300, hidden_layer_sizes=(80,),
              learning_rate_init=0.01, max_iter=30)
Best Parameters: {'activation': 'logistic', 'batch_size': 300, 'hidden_layer_sizes': (80,), 'learning_rate': 'constant', 'learning_rate_init': 0.01, 'max_iter': 30, 'solver': 'adam'}
===========================================================

Confusion Matrix:
-----------------

[[1186  405 1534  646]
 [ 379 2989 3121 1285]
 [ 872 1394 6414 2387]
 [ 310  828 3504 7110]]

Classification Report:
----------------------

              precision    recall  f1-score   support

   ambiguous       0.43      0.31      0.36      3771
    negative       0.53      0.38      0.45      7774
     neutral       0.44      0.58      0.50     11067
    positive       0.62      0.61      0.61     11752

    accuracy                           0.52     34364
   macro avg       0.51      0.47      0.48     34364
weighted avg       0.52      0.52      0.51     34364


